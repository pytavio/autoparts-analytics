import streamlit as st
import plotly.express as px
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
import pandas as pd
import os
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()

# Configura√ß√£o da p√°gina Streamlit (mantido seu estilo original)
st.set_page_config(
    page_title="Assistente RH - Analytics",
    page_icon="üë•",
    layout="wide"
)

# Estilo CSS personalizado (mantido do seu c√≥digo)
st.markdown("""
    <style>
    .main { padding: 2rem; }
    .stTextInput > div > div > input { padding: 0.5rem; }
    .chat-message { padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem; }
    .user-message { background-color: #e6f3ff; }
    .bot-message { background-color: #f0f2f6; }
    </style>
""", unsafe_allow_html=True)

class ClaudeHRSystem:
    
    def __init__(self):
        # Configura√ß√£o base do Claude
        self.base_config = {
            "anthropic_api_key": os.getenv('ANTHROPIC_API_KEY'),
            "temperature": 0.7,
            "model": "claude-3-opus-20240229"  # Usando o modelo mais recente
        }
        
        # Inicializa√ß√£o dos agentes especializados
        self.master_agent = ChatAnthropic(**self.base_config)
        self.hr_agent = ChatAnthropic(**self.base_config)
        self.data_agent = ChatAnthropic(**self.base_config)
        self.career_agent = ChatAnthropic(**self.base_config)
        
        # Templates especializados em portugu√™s
        self.master_prompt = ChatPromptTemplate.from_template("""
        Voc√™ √© o agente mestre do sistema de RH, especializado em an√°lise de dados.
        IMPORTANTE: RESPONDA SEMPRE EM PORTUGU√äS DO BRASIL.

        Analise os dados e coordene a resposta mais adequada:
        {available_data}

        Pergunta: {question}

        Forne√ßa uma an√°lise completa e profissional, sempre em portugu√™s.
        """)
        
        self.hr_prompt = ChatPromptTemplate.from_template("""
        Como especialista em RH, analise os dados focando em gest√£o de pessoas.
        RESPONDA EM PORTUGU√äS DO BRASIL.

        Dados: {available_data}
        Pergunta: {question}
        """)
        
        self.data_prompt = ChatPromptTemplate.from_template("""
        Como analista de dados de RH, forne√ßa insights quantitativos.
        RESPONDA EM PORTUGU√äS DO BRASIL.

        Dados: {available_data}
        Pergunta: {question}
        """)
        
        self.career_prompt = ChatPromptTemplate.from_template("""
        Como especialista em carreira e remunera√ß√£o, analise os dados.
        RESPONDA EM PORTUGU√äS DO BRASIL.

        Dados: {available_data}
        Pergunta: {question}
        """)
        
        # Chains
        self.master_chain = self.master_prompt | self.master_agent
        self.hr_chain = self.hr_prompt | self.hr_agent
        self.data_chain = self.data_prompt | self.data_agent
        self.career_chain = self.career_prompt | self.career_agent

    def process_query(self, query, data):
        """Processa a query usando os agentes especializados"""
        if not query or not isinstance(query, str):
            return "Por favor, forne√ßa uma pergunta v√°lida."
            
        try:
            # Determina qual agente usar baseado em palavras-chave
            query = query.lower()  # Converte para min√∫sculo uma √∫nica vez
            
            if any(word in query for word in ['cultura', 'equipe', 'gest√£o', 'clima']):
                specialist_chain = self.hr_chain
            elif any(word in query for word in ['m√©dia', 'n√∫mero', 'percentual', 'quantidade']):
                specialist_chain = self.data_chain
            elif any(word in query for word in ['sal√°rio', 'carreira', 'desenvolvimento', 'habilidades']):
                specialist_chain = self.career_chain
            else:
                specialist_chain = self.hr_chain

            # Obt√©m an√°lise especializada
            response = specialist_chain.invoke({
                "available_data": data.to_string(),
                "question": query
            })
            
            return response
            
        except Exception as e:
            return f"Erro ao processar a an√°lise: {str(e)}"
def generate_visualizations(df):
    """Gera visualiza√ß√µes com tratamento adequado dos dados"""
    col1, col2 = st.columns(2)
    
    with col1:
        # Gr√°fico de distribui√ß√£o por departamento
        fig_dept = px.pie(
            df['departamento'].value_counts().reset_index(),
            values='count',
            names='departamento',
            title='Distribui√ß√£o por Departamento'
        )
        st.plotly_chart(fig_dept, use_container_width=True)
        
    with col2:
        # Gr√°fico de sal√°rios por departamento
        fig_salary = px.box(
            df,
            x='departamento',
            y='salario',
            title='Distribui√ß√£o Salarial por Departamento'
        )
        st.plotly_chart(fig_salary, use_container_width=True)
    
    # Tratamento correto para as avalia√ß√µes sem warning
    try:
        # Primeiro, converte avalia√ß√µes se necess√°rio
        if isinstance(df['avaliacoes'].iloc[0], str):
            df['avaliacoes'] = df['avaliacoes'].apply(eval)
        
        # Calcula m√©dias por departamento sem gerar warning
        dept_ratings = df.groupby('departamento', group_keys=False).agg({
            'avaliacoes': lambda x: sum(sum(y)/len(y) for y in x)/len(x)
        }).reset_index()
        
        # Cria o gr√°fico de barras
        fig_ratings = px.bar(
            dept_ratings,
            x='departamento',
            y='avaliacoes',
            title='M√©dia de Avalia√ß√µes por Departamento'
        )
        fig_ratings.update_layout(yaxis_title='M√©dia de Avalia√ß√µes')
        st.plotly_chart(fig_ratings, use_container_width=True)
        
    except Exception as e:
        st.warning("N√£o foi poss√≠vel gerar o gr√°fico de avalia√ß√µes.")
        st.error(f"Erro: {str(e)}")

def format_claude_response(response):
    """Formata a resposta do Claude para exibi√ß√£o"""
    # Extrai apenas o conte√∫do da resposta
    if hasattr(response, 'content'):
        content = response.content
    elif isinstance(response, dict):
        content = response.get('content', str(response))
    else:
        content = str(response)
    
    # Remove metadados e formata o texto
    content = content.split('response_metadata')[0]  # Remove metadados
    content = content.replace('content=', '')  # Remove prefixo
    
    # Remove aspas extras se existirem
    content = content.strip("'\"")
    
    return content

def main():
    st.title("ü§ñ Assistente de RH Analytics - Powered by Claude")
    
    # Inicializa√ß√£o do sistema
    if 'agent_system' not in st.session_state:
        st.session_state.agent_system = ClaudeHRSystem()
    
    # Carrega dados
    df = pd.read_excel(os.path.join('E:\\Python\\LLM Local', 'dados_rh.xlsx'))
    
    # Sidebar com informa√ß√µes e filtros
    with st.sidebar:
        st.header("üìä Dados Gerais")
        st.write(f"Total de Funcion√°rios: {len(df)}")
        st.write(f"Departamentos: {', '.join(df['departamento'].unique())}")
        st.write(f"Faixa Salarial: R${df['salario'].min():,.2f} - R${df['salario'].max():,.2f}")
        
        st.header("üéØ Sugest√µes de Perguntas")
        st.write("- Qual departamento tem maior m√©dia salarial?")
        st.write("- Quais s√£o as habilidades mais comuns na TI?")
        st.write("- Como est√° o clima organizacional por departamento?")
        st.write("- Quais s√£o as tend√™ncias de desenvolvimento de carreira?")
    
    # √Årea principal
    tab1, tab2 = st.tabs(["üí¨ Chat com Claude", "üìà Visualiza√ß√µes"])

    with tab1:
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Exibe mensagens anteriores
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Input do usu√°rio e processamento
        if prompt := st.chat_input("Digite sua pergunta sobre os dados de RH..."):
            if prompt.strip():  # Verifica se n√£o √© string vazia
                # Adiciona mensagem do usu√°rio
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                # Processa e exibe resposta
                with st.chat_message("assistant"):
                    with st.spinner('Analisando dados com Claude...'):
                        try:
                            response = st.session_state.agent_system.process_query(prompt, df)
                            formatted_response = format_claude_response(response)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": formatted_response
                            })
                            st.markdown(formatted_response)
                        except Exception as e:
                            error_msg = f"Ocorreu um erro ao processar sua pergunta: {str(e)}"
                            st.error(error_msg)
                            st.session_state.messages.append({
                                "role": "assistant", 
                                "content": error_msg
                            })
            else:
                st.warning("Por favor, digite uma pergunta v√°lida.")
            
    with tab2:
        generate_visualizations(df)

if __name__ == "__main__":
    main()